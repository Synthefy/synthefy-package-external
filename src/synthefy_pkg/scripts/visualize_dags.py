#!/usr/bin/env python3
"""
Script to demonstrate DAG visualization from SCM priors.

uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type mlp_scm --n_features 10 --batch_size 4 --is_regression True
uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type tree_scm --n_features 10 --batch_size 4 --is_regression True
uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type mlp_scm --n_features 10 --batch_size 4 --is_regression True --network_specification_config src/synthefy_pkg/prior/config/network_configs/network_tiny.yaml
uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type mlp_scm --n_features 10 --batch_size 4 --is_regression True --config_path src/synthefy_pkg/prior/config/synthetic_configs/config_small_tabular.yaml
"""

import argparse
import os
from pathlib import Path

import numpy as np
import torch
import torch.nn as nn
import yaml
from omegaconf import DictConfig

from synthefy_pkg.configs.execution_configurations import Configuration
from synthefy_pkg.configs.tabicl_config import TabICLPriorConfig
from synthefy_pkg.prior.dataset import PriorDataset, SCMPrior
from synthefy_pkg.prior.genload import LoadPriorDataset
from synthefy_pkg.prior.mlp_scm import MLPSCM
from synthefy_pkg.prior.visualizations.ff_visualize import (
    visualize_dag,
    visualize_full_dag,
)
from synthefy_pkg.prior.visualizations.input_visualize import (
    visualize_dag_signals,
)
from synthefy_pkg.prior.visualizations.tree_visualize import (
    visualize_abbreviated_tree_scm,
    visualize_full_tree_scm,
)
from synthefy_pkg.prior.visualize import (
    visualize_batch_signals,
    visualize_batch_summary,
    visualize_stats,
)


def main():
    parser = argparse.ArgumentParser(
        description="Visualize DAGs from SCM priors"
    )
    parser.add_argument(
        "--tabular",
        action="store_true",
        help="Whether to use tabular data",
    )
    parser.add_argument(
        "--prior_type",
        type=str,
        default="mlp_scm",
        choices=["mlp_scm", "tree_scm", "mix_scm"],
        help="Type of prior to use",
    )
    parser.add_argument(
        "--n_features",
        type=int,
        default=10,
        help="Number of features in the DAG",
    )
    parser.add_argument(
        "--n_samples",
        type=int,
        default=1024,
        help="Number of samples to generate for data visualization",
    )
    parser.add_argument(
        "--batch_size",
        type=int,
        default=4,
        help="Number of DAGs to visualize in batch mode",
    )
    parser.add_argument(
        "--save_dir",
        type=str,
        default="figures/dags",
        help="Directory to save visualizations",
    )
    parser.add_argument(
        "--device", type=str, default="cpu", help="Device to use for generation"
    )
    parser.add_argument(
        "--is_regression",
        type=bool,
        default=False,
        help="Whether to use regression or classification",
    )
    parser.add_argument(
        "--visualization_type",
        type=str,
        default="both",
        choices=["full", "abbreviated", "both"],
        help="Type of visualization to generate for TreeSCM",
    )
    parser.add_argument(
        "--no_visualize_inputs",
        action="store_true",
        help="Whether to visualize input signal flow (only applicable for MLP SCM)",
    )
    parser.add_argument(
        "--config_path",
        type=str,
        default="src/synthefy_pkg/prior/config/synthetic_configs/config_small_tabular.yaml",
        help="Path to the configuration file",
    )
    parser.add_argument(
        "--network_specification_configs",
        type=str,
        default=[],
        nargs="+",
        help="Path to the network specification config file",
    )
    parser.add_argument(
        "--visualize_batch",
        type=bool,
        default=False,
        help="Whether to visualize in batch mode",
    )
    parser.add_argument(
        "--load_data_path",
        type=str,
        default=None,
        help="Path to the data to load (generated by genload.py)",
    )
    parser.add_argument(
        "--foundation_model_config",
        type=str,
        default="examples/configs/foundation_model_configs/grid_icl_training_configs/embedder_train_with_expert_forecast_real.yaml",
        help="Path to the foundation model configuration file",
    )
    args = parser.parse_args()

    # Create save directory
    save_dir = Path(args.save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)

    if args.is_regression:
        args.save_dir = args.save_dir + "_regression"

    # Get the DAGs from the dataset generation process
    dags = []
    datasets = list()
    target_values = list()
    indices_Xs = list()
    indices_ys = list()
    torch.manual_seed(0)
    np.random.seed(0)

    if args.load_data_path:
        # Create a configuration for loading the prior dataset
        config = TabICLPriorConfig(
            config_path=os.path.join(
                os.path.dirname(args.load_data_path), "prior_config.yaml"
            )
        )

        # Create LoadPriorDataset instance
        load_dataset = LoadPriorDataset(config=config, split="train")

        # Load data using the LoadPriorDataset
        for bidx, (X, y, d, seq_lens, train_sizes) in enumerate(load_dataset):
            X = X.detach()
            y = y.detach()
            d = d.detach()
            seq_lens = seq_lens.detach()
            train_sizes = train_sizes.detach()

            # Create series_flags tensor (assuming all are series data for now)
            series_flags = torch.ones(
                args.batch_size, dtype=torch.bool, device=args.device
            )

            # Visualize batch signals
            print("Visualizing batch signals...")
            visualize_batch_signals(
                X,
                y,
                d,
                seq_lens,
                train_sizes,
                save_dir=str(save_dir),
                batch_idx=bidx,
                show=False,
            )

            # Visualize batch summary
            print("Visualizing batch summary...")
            visualize_batch_summary(
                X,
                y,
                d,
                seq_lens,
                train_sizes,
                save_dir=str(save_dir),
                batch_idx=bidx,
                show=False,
            )

            # Only process the first batch for visualization
            exit()

    elif len(args.network_specification_configs) > 0:
        config_loc = args.foundation_model_config
        with open(config_loc, "r") as file:
            config = yaml.safe_load(file)
        config = DictConfig(config)

        configuration = Configuration(config=config)
        for config_path in args.network_specification_configs:
            if args.visualize_batch:
                config = TabICLPriorConfig.from_yaml(yaml_path=config_path)
                config.batch_size = args.batch_size
                config.n_features = args.n_features

                single_dataset = PriorDataset(
                    config=config,
                    real_data_config=configuration.dataset_config,
                    fm_config=configuration.foundation_model_config,
                )
                # Generate data to get the DAG
                result = single_dataset.get_batch(
                    batch_size=args.batch_size, node_info=True
                )
                assert len(result) == 8, (
                    f"Expected 8 values but got {len(result)}"
                )
                (
                    X,
                    y,
                    d,
                    seq_lens,
                    train_sizes,
                    series_flags,
                    node_info_array,
                    target_node_info_array,
                ) = result

                # Visualize batch signals
                print("Visualizing batch signals...")
                visualize_batch_signals(
                    X,
                    y,
                    d,
                    seq_lens,
                    train_sizes,
                    save_dir=str(save_dir),
                    batch_idx=0,
                    show=False,
                    node_info_array=node_info_array,
                    target_node_info_array=target_node_info_array,
                )

                # Visualize batch summary
                print("Visualizing batch summary...")
                visualize_batch_summary(
                    X,
                    y,
                    d,
                    seq_lens,
                    train_sizes,
                    save_dir=str(save_dir),
                    batch_idx=0,
                    show=False,
                )

                exit()

            else:
                mlpscm = MLPSCM(
                    yaml_path=config_path,
                    num_features=args.n_features,
                    batch_size=args.batch_size,
                    num_samples=args.n_samples,
                    is_regression=args.is_regression,
                    sampling="mixed" if args.tabular else "mixed_series",
                    used_sampler="ts" if not args.tabular else "tabular",
                )
                X, y, indices_X, indices_y = mlpscm(return_indices=True)
                dags.append(mlpscm)
                datasets.append(X.detach().clone())
                target_values.append(y.detach().clone())
                indices_Xs.append(indices_X.detach().clone())
                indices_ys.append(indices_y.detach().clone())
    else:
        for i in range(args.batch_size):
            # Create a new dataset with the same parameters to get the DAG
            while True:
                config = TabICLPriorConfig(config_path=args.config_path)
                config.prior_type = args.prior_type
                config.n_features = args.n_features
                config.is_regression = args.is_regression
                config.device = args.device
                config.batch_size = args.batch_size
                if args.tabular:
                    config.scm_used_sampler = {
                        "distribution": "meta_choice",
                        "choice_values": ["tabular"],
                    }
                    config.scm_sampling = {
                        "distribution": "meta_choice",
                        "choice_values": ["mixed"],
                    }
                else:
                    config.dataset_has_lag = 0.7
                single_dataset = PriorDataset(config=config)
                # Generate data to get the DAG
                result = single_dataset.get_batch(
                    batch_size=args.batch_size, node_info=True
                )
                assert len(result) == 8, (
                    f"Expected 8 values but got {len(result)}"
                )
                (
                    X,
                    y,
                    d,
                    seq_lens,
                    train_sizes,
                    series_flags,
                    node_info_array,
                    target_node_info_array,
                ) = result

                # Get the parameters from the dataset's prior
                assert isinstance(single_dataset.prior, SCMPrior)
                hp_sampling = single_dataset.prior.hp_sampling()
                sampled_hp = {
                    k: v() if callable(v) else v for k, v in hp_sampling.items()
                }
                params = {
                    **single_dataset.prior.fixed_hp,  # Fixed hyperparameters
                    **sampled_hp,
                    "seq_len": seq_lens[0].item(),
                    "train_size": train_sizes[0].item(),
                    "max_features": args.n_features,
                    "num_features": args.n_features,
                    "num_classes": 2,  # Default to binary classification
                    "prior_type": args.prior_type,
                    "is_regression": args.is_regression,
                    "device": args.device,
                    # no lagging for dag visualization
                    "original_seq_len": seq_lens[0].item(),
                    "lags": None,
                }

                # Generate dataset and get the DAG
                X, y, d, prior_object, params, indices_X, indices_y = (
                    single_dataset.prior.generate_dataset_object(params)
                )
                # handle tree scm
                if args.prior_type == "tree_scm":
                    if prior_object.hidden_dim**prior_object.num_layers > 150:
                        continue
                elif args.prior_type == "mlp_scm":
                    weight_dim = (
                        prior_object.layers[0][1].weight.shape[0]
                        if isinstance(prior_object.layers[0], nn.Sequential)
                        else prior_object.layers[0].weight.shape[0]
                    )
                    if (
                        prior_object.num_causes
                        + (len(prior_object.layers) - 1) * weight_dim
                        > 150
                    ):
                        continue
                datasets.append(X.clone())
                target_values.append(y.clone())
                dags.append(prior_object)
                indices_Xs.append(indices_X.clone())
                indices_ys.append(indices_y)
                break

    # Visualize individual DAGs
    for i, dag in enumerate(dags):
        if args.prior_type == "tree_scm":
            # For TreeSCM, use the specialized visualization functions
            if args.visualization_type in ["full", "both"]:
                full_save_path = save_dir / f"tree_full_dag_{i + 1}.png"
                visualize_full_tree_scm(
                    dag,
                    indices_X=indices_Xs[i],
                    indices_y=indices_ys[i],
                    save_path=str(full_save_path),
                    show=False,
                )

            if args.visualization_type in ["abbreviated", "both"]:
                abbrev_save_path = save_dir / f"tree_abbrev_dag_{i + 1}.png"
                visualize_abbreviated_tree_scm(
                    dag,
                    indices_X=indices_Xs[i],
                    indices_y=indices_ys[i],
                    save_path=str(abbrev_save_path),
                    show=False,
                )
        else:
            # For MLPSCM, use the original visualization functions
            # Save individual DAG visualization
            # Visualize input signals if requested
            if not args.no_visualize_inputs:
                visualize_dag_signals(
                    dag,
                    num_samples=args.n_samples,
                    output_dir=str(save_dir),
                    batch_idx=i,
                )

            save_path = save_dir / f"mlp_dag_{i + 1}.png"
            visualize_dag(
                dag,
                indices_X=indices_Xs[i],
                indices_y=indices_ys[i],
                save_path=str(save_path),
                show=False,
            )

            # Save DAG with data visualization
            data_save_path = save_dir / f"mlp_full_dag_{i + 1}.png"
            visualize_full_dag(
                dag,
                indices_X=indices_Xs[i],
                indices_y=indices_ys[i],
                save_path=str(data_save_path),
                show=False,
            )

        # Generate summary statistics
        visualize_stats(
            datasets[i],
            target_values[i],
            dag,
            save_path=str(save_dir / f"summary_stats_{i + 1}.png"),
            show=False,
        )

    print(f"Visualizations saved to {save_dir}")


if __name__ == "__main__":
    main()
    # uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type mlp_scm --n_features 10 --batch_size 4 --is_regression True
    # uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type tree_scm --n_features 10 --batch_size 4 --is_regression True
    # uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type mlp_scm --n_features 10 --batch_size 4 --is_regression True --network_specification_config src/synthefy_pkg/prior/config/network_configs/network_tiny.yaml
    # uv run src/synthefy_pkg/scripts/visualize_dags.py --prior_type mlp_scm --n_features 10 --batch_size 4 --is_regression True --config_path src/synthefy_pkg/prior/config/synthetic_configs/config_small_tabular.yaml
    # uv run src/synthefy_pkg/scripts/visualize_dags.py --visualize_batch True --batch_size 4 --network_specification_configs src/synthefy_pkg/prior/config/synthetic_configs/config_small_series.yaml
