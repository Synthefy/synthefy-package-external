{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthefy Inference Example\n",
        "\n",
        "This notebook demonstrates how to run synthesis and forecast inference with synthefy models.\n",
        "\n",
        "**Examples included:**\n",
        "1. Basic synthesis\n",
        "2. Basic forecast\n",
        "3. Forecast with zeroed-out columns (simulating future values what-if with only a subset of changes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:58: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
            "  import pynvml  # type: ignore[import]\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_type\" in SynthesisRequest has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_type\" in SynthesisResponse has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import List, Optional\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "os.environ[\"LICENSE_KEY\"] = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1dWlkIjoiYmE0NWY0MDQtZGMxOC00OTM3LWFiYTktYjBhYzcwOTRhMmMzIiwiaWF0IjoxNzY4MzM0MTk0LCJleHAiOjE3NzI0MDk1OTl9.D9LwSlNYnMTskIRbU5q26BdRFlPZ5vfGzYd1vbLk1GdeyveDJSHYX2xigbFPoRfPk5BmXq__8qjGOOyQcJ_ElD9vNMwy0mM4mVCVpa9lp6yfYsyq_sLVANNVG55xvSpkZ8m67Bk5nNQVz-D-eqKVMY4_6l93h00wOyiPVC72DT57nNgjj8CP9gWRtuS_AEboHfO6OcdKJPQ2XrWNlp8lOka9ABCkRXoHBMmOuAGtsCfFyjIiN_Y6u9dfMOo-74wo2IVUysI5-Nz5guA6AEnaTCpuQI7teXK_TgaojmZ09IuK3vmbyzxs-YoAhC4DIRM21HZRDAgJDIK1z-5UoBm6Dg\"\n",
        "os.environ[\"SYNTHEFY_DATASETS_BASE\"] = \"/home/raimi/data\"\n",
        "os.environ[\"SYNTHEFY_PACKAGE_BASE\"] = \"/home/raimi/synthefy-package-external\"\n",
        "\n",
        "\n",
        "\n",
        "# Add the api directory to path\n",
        "API_DIR = Path(\".\").resolve() / \"api\"\n",
        "sys.path.insert(0, str(API_DIR))\n",
        "\n",
        "from models import DataFrameModel, OneTimeSeries\n",
        "from services.config_loader import get_config_loader\n",
        "from services.demo_synthesis_service import DemoSynthesisService\n",
        "\n",
        "# Constants\n",
        "DEFAULT_DATASET = \"oura_subset\"\n",
        "DEFAULT_MODEL_TYPE = \"flexible\"\n",
        "DEFAULT_NUM_SAMPLES = 20\n",
        "DEFAULT_FORECAST_LENGTH = 96\n",
        "DEFAULT_GROUND_TRUTH_PREFIX = 0\n",
        "DEFAULT_SEED = 123\n",
        "FAKE_DATA_PATH = Path(\".\").resolve() / \"fake_oura_subset_data.parquet\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_seed(seed: Optional[int] = None) -> int:\n",
        "    \"\"\"Set random seed for reproducibility. Returns the seed used.\"\"\"\n",
        "    if seed is None:\n",
        "        seed = int(time.time() * 1000) % 100000 + random.randint(0, 10000)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    return seed\n",
        "\n",
        "\n",
        "def load_data(data_path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Load data from parquet file.\"\"\"\n",
        "    if not data_path.exists():\n",
        "        raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
        "    return pd.read_parquet(data_path)\n",
        "\n",
        "\n",
        "def timeseries_to_dataframe(timeseries_list: List[OneTimeSeries]) -> pd.DataFrame:\n",
        "    \"\"\"Convert list of OneTimeSeries to DataFrame.\"\"\"\n",
        "    return pd.DataFrame({\n",
        "        ts.name: [np.nan if v is None else v for v in ts.values]\n",
        "        for ts in timeseries_list\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keep_only_columns_for_forecast(\n",
        "    df: pd.DataFrame,\n",
        "    columns_to_keep: List[str],\n",
        "    forecast_length: int,\n",
        "    timeseries_columns: List[str],\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Keep only specified columns, zero out all other timeseries columns for the forecast horizon.\n",
        "\n",
        "    Use this when you want to forecast using only certain columns as known future values.\n",
        "    All other timeseries columns will be zeroed out in the last forecast_length rows.\n",
        "\n",
        "    Args:\n",
        "        df: Input DataFrame\n",
        "        columns_to_keep: List of column names to keep (not zero out)\n",
        "        forecast_length: Number of rows from the end to zero out\n",
        "        timeseries_columns: List of all timeseries column names\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with only specified columns having values in the forecast horizon\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    for col in timeseries_columns:\n",
        "        if col not in columns_to_keep and col in df.columns:\n",
        "            df.loc[df.index[-forecast_length:], col] = 0.0\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_inference(\n",
        "    task: str,\n",
        "    df: pd.DataFrame,\n",
        "    dataset_name: str = DEFAULT_DATASET,\n",
        "    model_type: str = DEFAULT_MODEL_TYPE,\n",
        "    num_samples: int = DEFAULT_NUM_SAMPLES,\n",
        "    forecast_length: int = DEFAULT_FORECAST_LENGTH,\n",
        "    ground_truth_prefix: int = DEFAULT_GROUND_TRUTH_PREFIX,\n",
        "    columns_to_keep: Optional[List[str]] = None,\n",
        "    seed: Optional[int] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Run synthesis or forecast inference with optional column masking.\n",
        "\n",
        "    Args:\n",
        "        task: \"synthesis\" or \"forecast\"\n",
        "        df: Input DataFrame (one window)\n",
        "        dataset_name: Dataset name for config loading\n",
        "        model_type: \"flexible\" or \"standard\"\n",
        "        num_samples: Number of synthesis runs to average\n",
        "        forecast_length: For forecast, number of time steps to predict\n",
        "        ground_truth_prefix: For synthesis, keep first N points from input\n",
        "        columns_to_keep: For forecast, only keep these columns (zero out all other timeseries columns)\n",
        "        seed: Random seed (None = time-based)\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with synthetic/forecasted time series\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        set_seed(seed)\n",
        "\n",
        "    # Get timeseries columns from config\n",
        "    config_loader = get_config_loader(dataset_name)\n",
        "    timeseries_cols = config_loader.get_required_columns().timeseries\n",
        "\n",
        "    # Apply column masking if specified (only keep specified columns, zero out others)\n",
        "    if columns_to_keep is not None and task == \"forecast\":\n",
        "        df = keep_only_columns_for_forecast(df, columns_to_keep, forecast_length, timeseries_cols)\n",
        "\n",
        "    # Initialize service\n",
        "    service = DemoSynthesisService(\n",
        "        dataset_name=dataset_name,\n",
        "        model_type=model_type,\n",
        "        task_type=task,\n",
        "    )\n",
        "\n",
        "    # Convert to DataFrameModel\n",
        "    columns = {col: df[col].tolist() for col in df.columns}\n",
        "    data_model = DataFrameModel(columns=columns)\n",
        "\n",
        "    # Run inference\n",
        "    if task == \"forecast\":\n",
        "        result = service.generate(\n",
        "            data=data_model,\n",
        "            num_samples=num_samples,\n",
        "            forecast_length=forecast_length,\n",
        "        )\n",
        "    else:\n",
        "        result = service.generate(\n",
        "            data=data_model,\n",
        "            num_samples=num_samples,\n",
        "            ground_truth_prefix_length=ground_truth_prefix,\n",
        "        )\n",
        "\n",
        "    return timeseries_to_dataframe(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data and Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-19 05:50:24.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.config_loader\u001b[0m:\u001b[36m_load_configs\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mLoading preprocessing config from: /home/raimi/synthefy-package-external/examples/configs/preprocessing_configs/config_oura_subset_preprocessing.json\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.config_loader\u001b[0m:\u001b[36m_load_configs\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mLoading synthesis config from: /home/raimi/synthefy-package-external/examples/configs/synthesis_configs/config_oura_subset_synthesis.yaml\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using seed: 123\n",
            "Window size: 192\n",
            "Timeseries columns: ['average_hrv', 'lowest_heart_rate', 'age_cva_diff']\n",
            "Data shape: (192, 15)\n"
          ]
        }
      ],
      "source": [
        "# Set seed for reproducibility\n",
        "seed = set_seed(DEFAULT_SEED)\n",
        "print(f\"Using seed: {seed}\")\n",
        "\n",
        "# Load config\n",
        "config_loader = get_config_loader(DEFAULT_DATASET)\n",
        "window_size = config_loader.get_window_size()\n",
        "required_cols = config_loader.get_required_columns()\n",
        "\n",
        "print(f\"Window size: {window_size}\")\n",
        "print(f\"Timeseries columns: {required_cols.timeseries}\")\n",
        "\n",
        "# Load data\n",
        "df = load_data(FAKE_DATA_PATH)\n",
        "if len(df) > window_size:\n",
        "    df = df.head(window_size).copy()\n",
        "print(f\"Data shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Basic Synthesis (Full Scenario Simulation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-19 05:50:24.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mInitializing DemoSynthesisService for dataset: oura_subset, model_type: flexible, task_type: synthesis\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mModel path: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking license key!\n",
            "License key check completed successfully.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-19 05:50:24.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mLoading scalers and encoders for dataset: oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoaded encoders: ['onehot']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.689\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36mget_configs\u001b[0m:\u001b[36m184\u001b[0m - \u001b[33m\u001b[1mUsing configuration from file: /home/raimi/synthefy-package-external/examples/configs/preprocessing_configs/config_oura_subset_preprocessing.json\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.690\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[33m\u001b[1mUsing DEFAULT output path: /home/raimi/data/oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.690\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m734\u001b[0m - \u001b[33m\u001b[1mMemory monitoring not enabled: invalid configuration\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_config\u001b[0m:\u001b[36m1071\u001b[0m - \u001b[1mTrain stride: 32, Val stride: 32, Test stride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.691\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m757\u001b[0m - \u001b[33m\u001b[1mShuffle is set to False in the preprocessing config file. Verify this is intended.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m764\u001b[0m - \u001b[1mWindow size: 192\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m765\u001b[0m - \u001b[1mStride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m767\u001b[0m - \u001b[1mGroup labels: ['user_id']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m768\u001b[0m - \u001b[1mTimeseries columns: 3\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m769\u001b[0m - \u001b[1mContinuous columns: 10\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m770\u001b[0m - \u001b[1mDiscrete columns: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.695\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.695\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `awake_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.696\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `age` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.696\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `low_activity_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.696\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `deep_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.697\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `sleep_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.697\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `restored_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.698\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `non_wear_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.698\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `rem_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.698\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `steps` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.699\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `active_calories` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.699\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.700\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `gender_male` of `discrete`, using default 'onehot' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.700\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.701\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mImporting data\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m814\u001b[0m - \u001b[1mUsing provided DataFrame\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m890\u001b[0m - \u001b[1mPrepreprocessing groups of df.shape=(192, 11)\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[numeric_cols] = group[numeric_cols].ffill().bfill().fillna(0)\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:545: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[categorical_cols] = group[categorical_cols].ffill().bfill()\n",
            "\u001b[32m2026-01-19 05:50:24.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m946\u001b[0m - \u001b[1mUpdated groups of processed_df.shape=(192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mClipping outliers with mean +/- 5SD\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m870\u001b[0m - \u001b[1mData loaded in 0.01 seconds; df.shape = (192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.711\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2019\u001b[0m - \u001b[33m\u001b[1mUsing stratified data split\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.712\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.713\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.713\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2072\u001b[0m - \u001b[1mReordering columns\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_discrete\u001b[0m:\u001b[36m1311\u001b[0m - \u001b[1monehot encoding cols: ['gender_male']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.717\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1267\u001b[0m - \u001b[33m\u001b[1mUsing saved encoder for: onehot\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1277\u001b[0m - \u001b[1monehot encoded cols: 2\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1518\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1357\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.721\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mgenerate_windows\u001b[0m:\u001b[36m312\u001b[0m - \u001b[33m\u001b[1mAbout to generate 1 windows - this may consume significant memory!\u001b[0m\n",
            "Generating windows: 100%|██████████| 1/1 [00:00<00:00, 3695.42it/s]\n",
            "\u001b[32m2026-01-19 05:50:24.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1397\u001b[0m - \u001b[1mFinished windowing, resulting: windows_3d_array.shape=(1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1524\u001b[0m - \u001b[1mDividing into window types\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1551\u001b[0m - \u001b[1mnum_timeseries: 0, num_continuous: 10, num_discrete: 2, num_original_discrete: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1554\u001b[0m - \u001b[1mtotal_windows.shape: (1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.814\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimeseries.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mcontinuous.shape = (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mdiscrete.shape = (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp_conditions.shape = (0,)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_discrete.shape = (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_text.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1657\u001b[0m - \u001b[1mFinished processing groups\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:24.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `continuous` with scalers: {'awake_mins': [{'scaler': StandardScaler()}], 'age': [{'scaler': StandardScaler()}], 'low_activity_time': [{'scaler': StandardScaler()}], 'deep_mins': [{'scaler': StandardScaler()}], 'sleep_duration': [{'scaler': StandardScaler()}], 'restored_duration': [{'scaler': StandardScaler()}], 'non_wear_time': [{'scaler': StandardScaler()}], 'rem_mins': [{'scaler': StandardScaler()}], 'steps': [{'scaler': StandardScaler()}], 'active_calories': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.586\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m262\u001b[0m - \u001b[34m\u001b[1mContinuous conditions shape: (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m265\u001b[0m - \u001b[34m\u001b[1mDiscrete conditions shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m266\u001b[0m - \u001b[34m\u001b[1mOriginal discrete shape: (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m430\u001b[0m - \u001b[1mRunning synthesis model inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m431\u001b[0m - \u001b[1mContinuous shape: (1, 192, 10), Discrete shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m463\u001b[0m - \u001b[1mRunning batched synthesis with 20 sample(s)...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:25.589\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m476\u001b[0m - \u001b[1mBatched conditions: continuous=(20, 192, 10), discrete=(20, 192, 2)\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/lightning_utilities/core/imports.py:14: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "\u001b[32m2026-01-19 05:50:30.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLoading synthesis config from: /home/raimi/synthefy-package-external/examples/configs/synthesis_configs/config_oura_subset_synthesis.yaml\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mSet random inference_seed: 34077\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mUsing denoiser: flexible_patched_diffusion_transformer for model_type: flexible\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mUsing task_type: synthesis\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.612\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.configs.dataset_configs\u001b[0m:\u001b[36mset_constraint_parameters\u001b[0m:\u001b[36m137\u001b[0m - \u001b[33m\u001b[1mWill use predetermined_constraint_values from saved constraints from preprocessing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.815\u001b[0m | \u001b[41m\u001b[1mCRITICAL\u001b[0m | \u001b[36msynthefy_pkg.experiments.experiment\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m101\u001b[0m - \u001b[41m\u001b[1mSetting logger level to DEBUG\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.experiment\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mLoading model for batched inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mGPU memory before setting up inference: 0.0MB allocated, 0.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mSetting seed for inference to 34077\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:30.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[94mloading model from checkpoint\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[32m2026-01-19 05:50:31.388\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1044\u001b[0m - \u001b[33m\u001b[1m\u001b[94mLoading model from checkpoint /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/utils/synthesis_utils.py:1056: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\n",
            "\u001b[32m2026-01-19 05:50:31.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1062\u001b[0m - \u001b[1mResuming from epoch: 3, global_step: 462\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\u001b[32m2026-01-19 05:50:32.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1073\u001b[0m - \u001b[1mModel loaded from checkpoint: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:58: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
            "  import pynvml  # type: ignore[import]\n",
            "Seed set to 34077\n",
            "\u001b[32m2026-01-19 05:50:33.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mGPU memory after setting up inference: 77.4MB allocated, 324.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:33.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m365\u001b[0m - \u001b[1mRunning batched synthesis on device=cuda, batch_size=20\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m488\u001b[0m - \u001b[1mBatched synthesis output shape: (20, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m501\u001b[0m - \u001b[1mSample diversity check: mean_abs_diff=1.169699, max_abs_diff=13.428703\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m507\u001b[0m - \u001b[1mAveraged 20 sample(s), output shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m519\u001b[0m - \u001b[1mUnscaled synthetic output\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synthesis result: (192, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_hrv_synthetic</th>\n",
              "      <th>lowest_heart_rate_synthetic</th>\n",
              "      <th>age_cva_diff_synthetic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46.536400</td>\n",
              "      <td>59.517017</td>\n",
              "      <td>4.961435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48.398342</td>\n",
              "      <td>60.349331</td>\n",
              "      <td>4.313553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42.895370</td>\n",
              "      <td>59.128708</td>\n",
              "      <td>4.225557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47.669170</td>\n",
              "      <td>61.216980</td>\n",
              "      <td>4.730634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46.187057</td>\n",
              "      <td>57.650761</td>\n",
              "      <td>4.729599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   average_hrv_synthetic  lowest_heart_rate_synthetic  age_cva_diff_synthetic\n",
              "0              46.536400                    59.517017                4.961435\n",
              "1              48.398342                    60.349331                4.313553\n",
              "2              42.895370                    59.128708                4.225557\n",
              "3              47.669170                    61.216980                4.730634\n",
              "4              46.187057                    57.650761                4.729599"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthesis_result = run_inference(\n",
        "    task=\"synthesis\",\n",
        "    df=df,\n",
        "    num_samples=DEFAULT_NUM_SAMPLES,\n",
        "    seed=DEFAULT_SEED,\n",
        ")\n",
        "print(f\"Synthesis result: {synthesis_result.shape}\")\n",
        "synthesis_result.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2: Basic Forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-19 05:50:38.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mInitializing DemoSynthesisService for dataset: oura_subset, model_type: flexible, task_type: forecast\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mModel path: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mLoading scalers and encoders for dataset: oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoaded encoders: ['onehot']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.642\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36mget_configs\u001b[0m:\u001b[36m184\u001b[0m - \u001b[33m\u001b[1mUsing configuration from file: /home/raimi/synthefy-package-external/examples/configs/preprocessing_configs/config_oura_subset_preprocessing.json\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.643\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[33m\u001b[1mUsing DEFAULT output path: /home/raimi/data/oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.643\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m734\u001b[0m - \u001b[33m\u001b[1mMemory monitoring not enabled: invalid configuration\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_config\u001b[0m:\u001b[36m1071\u001b[0m - \u001b[1mTrain stride: 32, Val stride: 32, Test stride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.644\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m757\u001b[0m - \u001b[33m\u001b[1mShuffle is set to False in the preprocessing config file. Verify this is intended.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m764\u001b[0m - \u001b[1mWindow size: 192\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m765\u001b[0m - \u001b[1mStride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m767\u001b[0m - \u001b[1mGroup labels: ['user_id']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m768\u001b[0m - \u001b[1mTimeseries columns: 3\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m769\u001b[0m - \u001b[1mContinuous columns: 10\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m770\u001b[0m - \u001b[1mDiscrete columns: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.648\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `awake_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.649\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `age` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.649\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `low_activity_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.649\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `deep_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.650\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `sleep_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.650\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `restored_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.650\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `non_wear_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.651\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `rem_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.651\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `steps` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.651\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `active_calories` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.652\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.652\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `gender_male` of `discrete`, using default 'onehot' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mImporting data\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m814\u001b[0m - \u001b[1mUsing provided DataFrame\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m890\u001b[0m - \u001b[1mPrepreprocessing groups of df.shape=(192, 11)\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[numeric_cols] = group[numeric_cols].ffill().bfill().fillna(0)\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:545: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[categorical_cols] = group[categorical_cols].ffill().bfill()\n",
            "\u001b[32m2026-01-19 05:50:38.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m946\u001b[0m - \u001b[1mUpdated groups of processed_df.shape=(192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mClipping outliers with mean +/- 5SD\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m870\u001b[0m - \u001b[1mData loaded in 0.01 seconds; df.shape = (192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.664\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2019\u001b[0m - \u001b[33m\u001b[1mUsing stratified data split\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.665\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.665\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.666\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.666\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.667\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.668\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2072\u001b[0m - \u001b[1mReordering columns\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_discrete\u001b[0m:\u001b[36m1311\u001b[0m - \u001b[1monehot encoding cols: ['gender_male']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.670\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1267\u001b[0m - \u001b[33m\u001b[1mUsing saved encoder for: onehot\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1277\u001b[0m - \u001b[1monehot encoded cols: 2\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1518\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.676\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1357\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.676\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mgenerate_windows\u001b[0m:\u001b[36m312\u001b[0m - \u001b[33m\u001b[1mAbout to generate 1 windows - this may consume significant memory!\u001b[0m\n",
            "Generating windows: 100%|██████████| 1/1 [00:00<00:00, 4346.43it/s]\n",
            "\u001b[32m2026-01-19 05:50:38.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1397\u001b[0m - \u001b[1mFinished windowing, resulting: windows_3d_array.shape=(1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1524\u001b[0m - \u001b[1mDividing into window types\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1551\u001b[0m - \u001b[1mnum_timeseries: 0, num_continuous: 10, num_discrete: 2, num_original_discrete: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:38.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1554\u001b[0m - \u001b[1mtotal_windows.shape: (1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimeseries.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mcontinuous.shape = (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mdiscrete.shape = (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp_conditions.shape = (0,)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_discrete.shape = (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_text.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1657\u001b[0m - \u001b[1mFinished processing groups\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `continuous` with scalers: {'awake_mins': [{'scaler': StandardScaler()}], 'age': [{'scaler': StandardScaler()}], 'low_activity_time': [{'scaler': StandardScaler()}], 'deep_mins': [{'scaler': StandardScaler()}], 'sleep_duration': [{'scaler': StandardScaler()}], 'restored_duration': [{'scaler': StandardScaler()}], 'non_wear_time': [{'scaler': StandardScaler()}], 'rem_mins': [{'scaler': StandardScaler()}], 'steps': [{'scaler': StandardScaler()}], 'active_calories': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.064\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m262\u001b[0m - \u001b[34m\u001b[1mContinuous conditions shape: (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.065\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m265\u001b[0m - \u001b[34m\u001b[1mDiscrete conditions shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.065\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m266\u001b[0m - \u001b[34m\u001b[1mOriginal discrete shape: (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m430\u001b[0m - \u001b[1mRunning synthesis model inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m431\u001b[0m - \u001b[1mContinuous shape: (1, 192, 10), Discrete shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m456\u001b[0m - \u001b[1mScaled timeseries for forecast, shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m463\u001b[0m - \u001b[1mRunning batched synthesis with 20 sample(s)...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m476\u001b[0m - \u001b[1mBatched conditions: continuous=(20, 192, 10), discrete=(20, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLoading synthesis config from: /home/raimi/synthefy-package-external/examples/configs/synthesis_configs/config_oura_subset_synthesis.yaml\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mSet random inference_seed: 39934\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mUsing denoiser: flexible_patched_diffusion_transformer for model_type: flexible\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mUsing task_type: forecast\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.084\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.configs.dataset_configs\u001b[0m:\u001b[36mset_constraint_parameters\u001b[0m:\u001b[36m137\u001b[0m - \u001b[33m\u001b[1mWill use predetermined_constraint_values from saved constraints from preprocessing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.experiment\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mLoading model for batched inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mGPU memory before setting up inference: 32.0MB allocated, 424.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mSetting seed for inference to 39934\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:39.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[94mloading model from checkpoint\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[32m2026-01-19 05:50:39.249\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1044\u001b[0m - \u001b[33m\u001b[1m\u001b[94mLoading model from checkpoint /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/utils/synthesis_utils.py:1056: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\n",
            "\u001b[32m2026-01-19 05:50:41.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1062\u001b[0m - \u001b[1mResuming from epoch: 3, global_step: 462\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\u001b[32m2026-01-19 05:50:43.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1073\u001b[0m - \u001b[1mModel loaded from checkpoint: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "Seed set to 39934\n",
            "\u001b[32m2026-01-19 05:50:43.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mGPU memory after setting up inference: 109.4MB allocated, 424.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:43.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mUsing forecast_length=50 for forecast task\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:43.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m365\u001b[0m - \u001b[1mRunning batched synthesis on device=cuda, batch_size=20\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m488\u001b[0m - \u001b[1mBatched synthesis output shape: (20, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m501\u001b[0m - \u001b[1mSample diversity check: mean_abs_diff=0.364549, max_abs_diff=4.886452\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m507\u001b[0m - \u001b[1mAveraged 20 sample(s), output shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m519\u001b[0m - \u001b[1mUnscaled synthetic output\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forecast result: (192, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_hrv_synthetic</th>\n",
              "      <th>lowest_heart_rate_synthetic</th>\n",
              "      <th>age_cva_diff_synthetic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.836437</td>\n",
              "      <td>50.716801</td>\n",
              "      <td>0.081839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.190922</td>\n",
              "      <td>58.026897</td>\n",
              "      <td>-2.004374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.882671</td>\n",
              "      <td>53.106018</td>\n",
              "      <td>1.481648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.253414</td>\n",
              "      <td>56.812786</td>\n",
              "      <td>-1.026426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.902901</td>\n",
              "      <td>61.765652</td>\n",
              "      <td>-0.457199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   average_hrv_synthetic  lowest_heart_rate_synthetic  age_cva_diff_synthetic\n",
              "0              51.836437                    50.716801                0.081839\n",
              "1              59.190922                    58.026897               -2.004374\n",
              "2              48.882671                    53.106018                1.481648\n",
              "3              48.253414                    56.812786               -1.026426\n",
              "4              49.902901                    61.765652               -0.457199"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "forecast_result = run_inference(\n",
        "    task=\"forecast\",\n",
        "    df=df,\n",
        "    forecast_length=50,\n",
        "    num_samples=DEFAULT_NUM_SAMPLES,\n",
        "    seed=DEFAULT_SEED,\n",
        ")\n",
        "print(f\"Forecast result: {forecast_result.shape}\")\n",
        "forecast_result.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 3: Forecast with Only Specific Columns\n",
        "\n",
        "Simulate a scenario where only some columns are known in the forecast horizon.\n",
        "All other timeseries columns are zeroed out for the last `forecast_length` rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Columns to keep: ['average_hrv', 'lowest_heart_rate']\n",
            "Example zeroed column: age_cva_diff\n",
            "\n",
            "Original values (last 5 rows):\n",
            "187   -0.006161\n",
            "188    5.103895\n",
            "189    1.003879\n",
            "190    2.232057\n",
            "191    3.500400\n",
            "Name: age_cva_diff, dtype: float64\n",
            "\n",
            "After zeroing out:\n",
            "187    0.0\n",
            "188    0.0\n",
            "189    0.0\n",
            "190    0.0\n",
            "191    0.0\n",
            "Name: age_cva_diff, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Only keep these columns for the forecast horizon (others will be zeroed out)\n",
        "columns_to_keep = [\"average_hrv\", \"lowest_heart_rate\"]\n",
        "forecast_length = 50\n",
        "\n",
        "# Show what zeroing out looks like\n",
        "df_partial = keep_only_columns_for_forecast(df, columns_to_keep, forecast_length, required_cols.timeseries)\n",
        "\n",
        "# Show a column that will be zeroed\n",
        "zeroed_col = [c for c in required_cols.timeseries if c not in columns_to_keep][0]\n",
        "print(f\"Columns to keep: {columns_to_keep}\")\n",
        "print(f\"Example zeroed column: {zeroed_col}\")\n",
        "print(f\"\\nOriginal values (last 5 rows):\")\n",
        "print(df[zeroed_col].tail())\n",
        "print(f\"\\nAfter zeroing out:\")\n",
        "print(df_partial[zeroed_col].tail())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-19 05:50:47.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mInitializing DemoSynthesisService for dataset: oura_subset, model_type: flexible, task_type: forecast\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mModel path: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mLoading scalers and encoders for dataset: oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoaded encoders: ['onehot']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.393\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36mget_configs\u001b[0m:\u001b[36m184\u001b[0m - \u001b[33m\u001b[1mUsing configuration from file: /home/raimi/synthefy-package-external/examples/configs/preprocessing_configs/config_oura_subset_preprocessing.json\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.394\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[33m\u001b[1mUsing DEFAULT output path: /home/raimi/data/oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.394\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m734\u001b[0m - \u001b[33m\u001b[1mMemory monitoring not enabled: invalid configuration\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_config\u001b[0m:\u001b[36m1071\u001b[0m - \u001b[1mTrain stride: 32, Val stride: 32, Test stride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.395\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m757\u001b[0m - \u001b[33m\u001b[1mShuffle is set to False in the preprocessing config file. Verify this is intended.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m764\u001b[0m - \u001b[1mWindow size: 192\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m765\u001b[0m - \u001b[1mStride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m767\u001b[0m - \u001b[1mGroup labels: ['user_id']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m768\u001b[0m - \u001b[1mTimeseries columns: 3\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m769\u001b[0m - \u001b[1mContinuous columns: 10\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m770\u001b[0m - \u001b[1mDiscrete columns: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.399\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `awake_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.400\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `age` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.400\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `low_activity_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.401\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `deep_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.401\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `sleep_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.401\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `restored_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.402\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `non_wear_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.402\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `rem_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.402\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `steps` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.402\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `active_calories` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.404\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `gender_male` of `discrete`, using default 'onehot' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mImporting data\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m814\u001b[0m - \u001b[1mUsing provided DataFrame\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m890\u001b[0m - \u001b[1mPrepreprocessing groups of df.shape=(192, 11)\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[numeric_cols] = group[numeric_cols].ffill().bfill().fillna(0)\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:545: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[categorical_cols] = group[categorical_cols].ffill().bfill()\n",
            "\u001b[32m2026-01-19 05:50:47.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m946\u001b[0m - \u001b[1mUpdated groups of processed_df.shape=(192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mClipping outliers with mean +/- 5SD\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m870\u001b[0m - \u001b[1mData loaded in 0.01 seconds; df.shape = (192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2019\u001b[0m - \u001b[33m\u001b[1mUsing stratified data split\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.415\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.416\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.416\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2072\u001b[0m - \u001b[1mReordering columns\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_discrete\u001b[0m:\u001b[36m1311\u001b[0m - \u001b[1monehot encoding cols: ['gender_male']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.421\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1267\u001b[0m - \u001b[33m\u001b[1mUsing saved encoder for: onehot\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1277\u001b[0m - \u001b[1monehot encoded cols: 2\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1518\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1357\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.425\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mgenerate_windows\u001b[0m:\u001b[36m312\u001b[0m - \u001b[33m\u001b[1mAbout to generate 1 windows - this may consume significant memory!\u001b[0m\n",
            "Generating windows: 100%|██████████| 1/1 [00:00<00:00, 4262.50it/s]\n",
            "\u001b[32m2026-01-19 05:50:47.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1397\u001b[0m - \u001b[1mFinished windowing, resulting: windows_3d_array.shape=(1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1524\u001b[0m - \u001b[1mDividing into window types\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1551\u001b[0m - \u001b[1mnum_timeseries: 0, num_continuous: 10, num_discrete: 2, num_original_discrete: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1554\u001b[0m - \u001b[1mtotal_windows.shape: (1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimeseries.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mcontinuous.shape = (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mdiscrete.shape = (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp_conditions.shape = (0,)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_discrete.shape = (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_text.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1657\u001b[0m - \u001b[1mFinished processing groups\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `continuous` with scalers: {'awake_mins': [{'scaler': StandardScaler()}], 'age': [{'scaler': StandardScaler()}], 'low_activity_time': [{'scaler': StandardScaler()}], 'deep_mins': [{'scaler': StandardScaler()}], 'sleep_duration': [{'scaler': StandardScaler()}], 'restored_duration': [{'scaler': StandardScaler()}], 'non_wear_time': [{'scaler': StandardScaler()}], 'rem_mins': [{'scaler': StandardScaler()}], 'steps': [{'scaler': StandardScaler()}], 'active_calories': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.841\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m262\u001b[0m - \u001b[34m\u001b[1mContinuous conditions shape: (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.842\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m265\u001b[0m - \u001b[34m\u001b[1mDiscrete conditions shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.842\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m266\u001b[0m - \u001b[34m\u001b[1mOriginal discrete shape: (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m430\u001b[0m - \u001b[1mRunning synthesis model inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m431\u001b[0m - \u001b[1mContinuous shape: (1, 192, 10), Discrete shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m456\u001b[0m - \u001b[1mScaled timeseries for forecast, shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m463\u001b[0m - \u001b[1mRunning batched synthesis with 20 sample(s)...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m476\u001b[0m - \u001b[1mBatched conditions: continuous=(20, 192, 10), discrete=(20, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLoading synthesis config from: /home/raimi/synthefy-package-external/examples/configs/synthesis_configs/config_oura_subset_synthesis.yaml\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mSet random inference_seed: 48710\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mUsing denoiser: flexible_patched_diffusion_transformer for model_type: flexible\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mUsing task_type: forecast\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.860\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.configs.dataset_configs\u001b[0m:\u001b[36mset_constraint_parameters\u001b[0m:\u001b[36m137\u001b[0m - \u001b[33m\u001b[1mWill use predetermined_constraint_values from saved constraints from preprocessing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.experiment\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mLoading model for batched inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mGPU memory before setting up inference: 32.0MB allocated, 424.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mSetting seed for inference to 48710\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:47.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[94mloading model from checkpoint\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[32m2026-01-19 05:50:48.019\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1044\u001b[0m - \u001b[33m\u001b[1m\u001b[94mLoading model from checkpoint /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/utils/synthesis_utils.py:1056: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\n",
            "\u001b[32m2026-01-19 05:50:49.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1062\u001b[0m - \u001b[1mResuming from epoch: 3, global_step: 462\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\u001b[32m2026-01-19 05:50:51.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1073\u001b[0m - \u001b[1mModel loaded from checkpoint: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "Seed set to 48710\n",
            "\u001b[32m2026-01-19 05:50:51.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mGPU memory after setting up inference: 109.4MB allocated, 424.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:51.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mUsing forecast_length=50 for forecast task\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:51.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m365\u001b[0m - \u001b[1mRunning batched synthesis on device=cuda, batch_size=20\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m488\u001b[0m - \u001b[1mBatched synthesis output shape: (20, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m501\u001b[0m - \u001b[1mSample diversity check: mean_abs_diff=0.320216, max_abs_diff=4.832526\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m507\u001b[0m - \u001b[1mAveraged 20 sample(s), output shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m519\u001b[0m - \u001b[1mUnscaled synthetic output\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forecast with only ['average_hrv', 'lowest_heart_rate']: (192, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_hrv_synthetic</th>\n",
              "      <th>lowest_heart_rate_synthetic</th>\n",
              "      <th>age_cva_diff_synthetic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.836437</td>\n",
              "      <td>50.716801</td>\n",
              "      <td>0.081839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.190922</td>\n",
              "      <td>58.026897</td>\n",
              "      <td>-2.004374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.882671</td>\n",
              "      <td>53.106018</td>\n",
              "      <td>1.481648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.253414</td>\n",
              "      <td>56.812786</td>\n",
              "      <td>-1.026426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.902901</td>\n",
              "      <td>61.765652</td>\n",
              "      <td>-0.457199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   average_hrv_synthetic  lowest_heart_rate_synthetic  age_cva_diff_synthetic\n",
              "0              51.836437                    50.716801                0.081839\n",
              "1              59.190922                    58.026897               -2.004374\n",
              "2              48.882671                    53.106018                1.481648\n",
              "3              48.253414                    56.812786               -1.026426\n",
              "4              49.902901                    61.765652               -0.457199"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run forecast keeping only specified columns\n",
        "forecast_partial = run_inference(\n",
        "    task=\"forecast\",\n",
        "    df=df,\n",
        "    forecast_length=forecast_length,\n",
        "    columns_to_keep=columns_to_keep,  # Only keep these, zero out others\n",
        "    num_samples=DEFAULT_NUM_SAMPLES,\n",
        "    seed=DEFAULT_SEED,\n",
        ")\n",
        "print(f\"Forecast with only {columns_to_keep}: {forecast_partial.shape}\")\n",
        "forecast_partial.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Forecast with Single Column Only\n",
        "\n",
        "Forecast with minimal information - only one target column has future values. (same as regular forecast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2026-01-19 05:50:56.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mInitializing DemoSynthesisService for dataset: oura_subset, model_type: flexible, task_type: forecast\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m130\u001b[0m - \u001b[1mModel path: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mLoading scalers and encoders for dataset: oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_load_scalers_and_encoders\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mLoaded encoders: ['onehot']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.616\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36mget_configs\u001b[0m:\u001b[36m184\u001b[0m - \u001b[33m\u001b[1mUsing configuration from file: /home/raimi/synthefy-package-external/examples/configs/preprocessing_configs/config_oura_subset_preprocessing.json\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.617\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.base_config\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[33m\u001b[1mUsing DEFAULT output path: /home/raimi/data/oura_subset\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.617\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m734\u001b[0m - \u001b[33m\u001b[1mMemory monitoring not enabled: invalid configuration\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_config\u001b[0m:\u001b[36m1071\u001b[0m - \u001b[1mTrain stride: 32, Val stride: 32, Test stride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.618\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m757\u001b[0m - \u001b[33m\u001b[1mShuffle is set to False in the preprocessing config file. Verify this is intended.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m764\u001b[0m - \u001b[1mWindow size: 192\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m765\u001b[0m - \u001b[1mStride: 32\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m767\u001b[0m - \u001b[1mGroup labels: ['user_id']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m768\u001b[0m - \u001b[1mTimeseries columns: 3\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m769\u001b[0m - \u001b[1mContinuous columns: 10\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m770\u001b[0m - \u001b[1mDiscrete columns: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.620\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.621\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `awake_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.621\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `age` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.622\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `low_activity_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.622\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `deep_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.622\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `sleep_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.622\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `restored_duration` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.623\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `non_wear_time` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.624\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `rem_mins` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.624\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `steps` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.624\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `active_calories` of `continuous`, using default 'standard' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.625\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1153\u001b[0m - \u001b[33m\u001b[1mScaler info not specified for `gender_male` of `discrete`, using default 'onehot' scaler info.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m792\u001b[0m - \u001b[1mImporting data\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m814\u001b[0m - \u001b[1mUsing provided DataFrame\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m890\u001b[0m - \u001b[1mPrepreprocessing groups of df.shape=(192, 11)\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:543: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[numeric_cols] = group[numeric_cols].ffill().bfill().fillna(0)\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/preprocessing/preprocess.py:545: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  group[categorical_cols] = group[categorical_cols].ffill().bfill()\n",
            "\u001b[32m2026-01-19 05:50:56.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups_and_timestamps\u001b[0m:\u001b[36m946\u001b[0m - \u001b[1mUpdated groups of processed_df.shape=(192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mClipping outliers with mean +/- 5SD\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mload_and_prep_rawdata\u001b[0m:\u001b[36m870\u001b[0m - \u001b[1mData loaded in 0.01 seconds; df.shape = (192, 11)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.635\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2019\u001b[0m - \u001b[33m\u001b[1mUsing stratified data split\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `timeseries` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `timeseries`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `continuous` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `continuous`: {'awake_mins': {'scaler_type': 'standard'}, 'age': {'scaler_type': 'standard'}, 'low_activity_time': {'scaler_type': 'standard'}, 'deep_mins': {'scaler_type': 'standard'}, 'sleep_duration': {'scaler_type': 'standard'}, 'restored_duration': {'scaler_type': 'standard'}, 'non_wear_time': {'scaler_type': 'standard'}, 'rem_mins': {'scaler_type': 'standard'}, 'steps': {'scaler_type': 'standard'}, 'active_calories': {'scaler_type': 'standard'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `discrete` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.637\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1187\u001b[0m - \u001b[34m\u001b[1mOrdered scalers_info for `discrete`: {'gender_male': {'scaler_type': 'onehot'}}.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1140\u001b[0m - \u001b[1mValidating `group_labels` scalers info\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.637\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1145\u001b[0m - \u001b[34m\u001b[1mNo columns to validate for `group_labels`.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mvalidate_scalers\u001b[0m:\u001b[36m1191\u001b[0m - \u001b[1mScalers and encoders validated successfully.\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_data\u001b[0m:\u001b[36m2072\u001b[0m - \u001b[1mReordering columns\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_discrete\u001b[0m:\u001b[36m1311\u001b[0m - \u001b[1monehot encoding cols: ['gender_male']\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.640\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1267\u001b[0m - \u001b[33m\u001b[1mUsing saved encoder for: onehot\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mencode_by_type\u001b[0m:\u001b[36m1277\u001b[0m - \u001b[1monehot encoded cols: 2\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1518\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1357\u001b[0m - \u001b[1mStarted windowing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.644\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mgenerate_windows\u001b[0m:\u001b[36m312\u001b[0m - \u001b[33m\u001b[1mAbout to generate 1 windows - this may consume significant memory!\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All timeseries columns: ['average_hrv', 'lowest_heart_rate', 'age_cva_diff']\n",
            "Keeping only: [average_hrv]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating windows: 100%|██████████| 1/1 [00:00<00:00, 3160.74it/s]\n",
            "\u001b[32m2026-01-19 05:50:56.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mreshape_for_timeseries\u001b[0m:\u001b[36m1397\u001b[0m - \u001b[1mFinished windowing, resulting: windows_3d_array.shape=(1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1524\u001b[0m - \u001b[1mDividing into window types\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1551\u001b[0m - \u001b[1mnum_timeseries: 0, num_continuous: 10, num_discrete: 2, num_original_discrete: 1\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1554\u001b[0m - \u001b[1mtotal_windows.shape: (1, 192, 13)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:56.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimeseries.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mcontinuous.shape = (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mdiscrete.shape = (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1mtimestamp_conditions.shape = (0,)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_discrete.shape = (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1625\u001b[0m - \u001b[1moriginal_text.shape = (1, 192, 0)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.preprocessing.preprocess\u001b[0m:\u001b[36mprocess_groups\u001b[0m:\u001b[36m1657\u001b[0m - \u001b[1mFinished processing groups\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `continuous` with scalers: {'awake_mins': [{'scaler': StandardScaler()}], 'age': [{'scaler': StandardScaler()}], 'low_activity_time': [{'scaler': StandardScaler()}], 'deep_mins': [{'scaler': StandardScaler()}], 'sleep_duration': [{'scaler': StandardScaler()}], 'restored_duration': [{'scaler': StandardScaler()}], 'non_wear_time': [{'scaler': StandardScaler()}], 'rem_mins': [{'scaler': StandardScaler()}], 'steps': [{'scaler': StandardScaler()}], 'active_calories': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m262\u001b[0m - \u001b[34m\u001b[1mContinuous conditions shape: (1, 192, 10)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.004\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m265\u001b[0m - \u001b[34m\u001b[1mDiscrete conditions shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.005\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_prepare_conditions\u001b[0m:\u001b[36m266\u001b[0m - \u001b[34m\u001b[1mOriginal discrete shape: (1, 192, 1)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m430\u001b[0m - \u001b[1mRunning synthesis model inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m431\u001b[0m - \u001b[1mContinuous shape: (1, 192, 10), Discrete shape: (1, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m456\u001b[0m - \u001b[1mScaled timeseries for forecast, shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m463\u001b[0m - \u001b[1mRunning batched synthesis with 20 sample(s)...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m476\u001b[0m - \u001b[1mBatched conditions: continuous=(20, 192, 10), discrete=(20, 192, 2)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m172\u001b[0m - \u001b[1mLoading synthesis config from: /home/raimi/synthefy-package-external/examples/configs/synthesis_configs/config_oura_subset_synthesis.yaml\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m196\u001b[0m - \u001b[1mSet random inference_seed: 57872\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mUsing denoiser: flexible_patched_diffusion_transformer for model_type: flexible\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mexperiment\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mUsing task_type: forecast\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.022\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.configs.dataset_configs\u001b[0m:\u001b[36mset_constraint_parameters\u001b[0m:\u001b[36m137\u001b[0m - \u001b[33m\u001b[1mWill use predetermined_constraint_values from saved constraints from preprocessing\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.experiment\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m108\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m311\u001b[0m - \u001b[1mLoading model for batched inference...\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m119\u001b[0m - \u001b[1mGPU memory before setting up inference: 32.0MB allocated, 424.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m122\u001b[0m - \u001b[1mSetting seed for inference to 57872\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1m\u001b[94mloading model from checkpoint\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "\u001b[32m2026-01-19 05:50:57.207\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1044\u001b[0m - \u001b[33m\u001b[1m\u001b[94mLoading model from checkpoint /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\u001b[0m\n",
            "/home/raimi/synthefy-package-external/src/synthefy_pkg/utils/synthesis_utils.py:1056: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\n",
            "\u001b[32m2026-01-19 05:50:57.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1062\u001b[0m - \u001b[1mResuming from epoch: 3, global_step: 462\u001b[0m\n",
            "/home/raimi/synthefy-package-external/.venv/lib/python3.11/site-packages/lightning/fabric/utilities/cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\u001b[32m2026-01-19 05:50:57.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.synthesis_utils\u001b[0m:\u001b[36mload_synthesis_model\u001b[0m:\u001b[36m1073\u001b[0m - \u001b[1mModel loaded from checkpoint: /home/raimi/data/training_logs/oura_subset/Time_Series_Diffusion_Training/synthesis_oura_subset_flexible/checkpoints/best_model.ckpt\u001b[0m\n",
            "Seed set to 57872\n",
            "\u001b[32m2026-01-19 05:50:57.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.experiments.synthesis_experiment\u001b[0m:\u001b[36m_setup_inference\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1mGPU memory after setting up inference: 109.4MB allocated, 424.0MB reserved\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mUsing forecast_length=50 for forecast task\u001b[0m\n",
            "\u001b[32m2026-01-19 05:50:57.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36m_generate_batch\u001b[0m:\u001b[36m365\u001b[0m - \u001b[1mRunning batched synthesis on device=cuda, batch_size=20\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m488\u001b[0m - \u001b[1mBatched synthesis output shape: (20, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m501\u001b[0m - \u001b[1mSample diversity check: mean_abs_diff=0.293389, max_abs_diff=3.873758\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m507\u001b[0m - \u001b[1mAveraged 20 sample(s), output shape: (1, 3, 192)\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m550\u001b[0m - \u001b[1mLoading scalers for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m574\u001b[0m - \u001b[1mLoading column names for timeseries\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msynthefy_pkg.utils.scaling_utils\u001b[0m:\u001b[36mtransform_using_scaler\u001b[0m:\u001b[36m616\u001b[0m - \u001b[1mTransforming windows of type `timeseries` with scalers: {'average_hrv': [{'scaler': StandardScaler()}], 'lowest_heart_rate': [{'scaler': StandardScaler()}], 'age_cva_diff': [{'scaler': StandardScaler()}]}\u001b[0m\n",
            "\u001b[32m2026-01-19 05:51:01.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mservices.demo_synthesis_service\u001b[0m:\u001b[36mgenerate\u001b[0m:\u001b[36m519\u001b[0m - \u001b[1mUnscaled synthetic output\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Forecast with single column: (192, 3)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_hrv_synthetic</th>\n",
              "      <th>lowest_heart_rate_synthetic</th>\n",
              "      <th>age_cva_diff_synthetic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51.836437</td>\n",
              "      <td>50.716801</td>\n",
              "      <td>0.081839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59.190922</td>\n",
              "      <td>58.026897</td>\n",
              "      <td>-2.004374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48.882671</td>\n",
              "      <td>53.106018</td>\n",
              "      <td>1.481648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>48.253414</td>\n",
              "      <td>56.812786</td>\n",
              "      <td>-1.026426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>49.902901</td>\n",
              "      <td>61.765652</td>\n",
              "      <td>-0.457199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   average_hrv_synthetic  lowest_heart_rate_synthetic  age_cva_diff_synthetic\n",
              "0              51.836437                    50.716801                0.081839\n",
              "1              59.190922                    58.026897               -2.004374\n",
              "2              48.882671                    53.106018                1.481648\n",
              "3              48.253414                    56.812786               -1.026426\n",
              "4              49.902901                    61.765652               -0.457199"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Keep only one target column\n",
        "target_column = \"average_hrv\"\n",
        "\n",
        "print(f\"All timeseries columns: {required_cols.timeseries}\")\n",
        "print(f\"Keeping only: [{target_column}]\")\n",
        "\n",
        "# Run forecast with only the target column\n",
        "forecast_single = run_inference(\n",
        "    task=\"forecast\",\n",
        "    df=df,\n",
        "    forecast_length=50,\n",
        "    columns_to_keep=[target_column],  # Only keep this one column\n",
        "    num_samples=DEFAULT_NUM_SAMPLES,\n",
        "    seed=DEFAULT_SEED,\n",
        ")\n",
        "print(f\"\\nForecast with single column: {forecast_single.shape}\")\n",
        "forecast_single.head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
