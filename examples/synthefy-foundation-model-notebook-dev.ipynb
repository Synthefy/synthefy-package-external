{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthefy Forecasting API: A Comprehensive Guide\n",
    "\n",
    "Welcome to the Synthefy Forecasting API! This notebook demonstrates how to use our powerful forecasting capabilities to predict time series data with advanced features like context-aware forecasting and external data integration.\n",
    "\n",
    "## What is Synthefy?\n",
    "\n",
    "Synthefy is an advanced forecasting API that leverages foundation models to provide accurate predictions for your time series data. Our API offers:\n",
    "\n",
    "- **Simple Integration**: Easy-to-use Python interface\n",
    "- **Context-Aware Forecasting**: Incorporate future known data into your predictions\n",
    "- **External Data Integration**: Leverage Haver Analytics data for enhanced predictions\n",
    "- **Flexible Input**: Support for multiple targets and covariates\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "First, let's set up our environment and import the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minkyu/repos/synthefy-package/.venv/lib/python3.11/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_type\" in FoundationModelForecastStreamRequest has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import httpx\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "# --------------------------------------------------- Setup API ---------------------------------------------------\n",
    "X_API_KEY = \"254316e6638ae1f39897cc84f5de86b4cf347ff17611b96d42c8161f57d1a01e\"  # Replace with your API key\n",
    "BASE_URL = \"https://dev.synthefy.com\"\n",
    "client = httpx.Client(base_url=BASE_URL, timeout=100.0)\n",
    "ENDPOINT = \"api/foundation_models/forecast/stream\"\n",
    "\n",
    "# --------------------------------------------------- End API Setup ---------------------------------------------------\n",
    "\n",
    "# ## Understanding the Data Models\n",
    "#\n",
    "# Our API uses Pydantic models to ensure data validation and type safety. Let's explore the key components:\n",
    "\n",
    "\n",
    "# --------------------------------------------------- Data Model(s) ---------------------------------------------------\n",
    "class HaverMetadataAccessInfo(BaseModel):\n",
    "    \"\"\"Model for accessing Haver Analytics data.\n",
    "\n",
    "    This model allows you to specify which external data sources you want to use\n",
    "    for enhancing your forecasts.\n",
    "    \"\"\"\n",
    "\n",
    "    db_path_info: Optional[str] = None\n",
    "    access_info: Dict[str, Any]\n",
    "\n",
    "    @field_validator(\"access_info\")\n",
    "    @classmethod\n",
    "    def validate_access_info(cls, v: Dict[str, Any]):\n",
    "        if not v:\n",
    "            raise ValueError(\"access_info must not be empty\")\n",
    "        if not ((\"file_name\" in v) or (\"databaseName\" in v and \"name\" in v)):\n",
    "            raise ValueError(\n",
    "                \"Each access_info item must contain either 'file_name' or both 'databaseName' and 'name'\"\n",
    "            )\n",
    "        return v\n",
    "\n",
    "\n",
    "class FoundationModelForecastStreamRequest(BaseModel):\n",
    "    # --------------- User uploaded data ---------------\n",
    "    historical_timestamps: List[str]\n",
    "\n",
    "    # from df.to_dict(orient='list')\n",
    "    historical_timeseries_data: Dict[str, List[Any]]\n",
    "    targets: List[str]  # must be present as keys in historical_timeseries_data\n",
    "\n",
    "    # must be present in historical_timeseries_data if provided\n",
    "    covariates: List[str] = Field(default_factory=list)\n",
    "    # --------------- End user uploaded data ---------------\n",
    "\n",
    "    # --------------- Synthefy Database context ---------------\n",
    "    synthefy_metadata_info_combined: List[HaverMetadataAccessInfo] | None\n",
    "    # Must be a subset of synthefy_metadata_list; these will be leaked into the future_df\n",
    "    synthefy_metadata_leak_idxs: Optional[List[int]] = None\n",
    "    # --------------- End Synthefy Database context ---------------\n",
    "\n",
    "    # --------------- Data for Forecasting ---------------\n",
    "    # the timestamps for which we want to predict the targets' values\n",
    "    forecast_timestamps: List[str]\n",
    "    # from df.to_dict(orient='list'); future metadata that will be used\n",
    "    future_timeseries_data: Dict[str, List[Any]] | None\n",
    "    # --------------- End Data for Forecasting ---------------\n",
    "\n",
    "    # Dict used to add constant context (will be same for each timestamp/repeated for the dfs)\n",
    "    static_context: Dict[str, float | int | str] | None\n",
    "    prompt: str | None  # Prompt/description of the task/data/etc\n",
    "\n",
    "    quantiles: List[float] | None  # which quantiles to return\n",
    "    model_type: str = Field(\n",
    "        default=\"tabpfn\",\n",
    "        description=\"Model type to use for forecasting. Options: 'tabpfn', 'synthefy'\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def make_api_call(request: FoundationModelForecastStreamRequest):\n",
    "# Make the API call\n",
    "    response = client.post(\n",
    "        ENDPOINT,\n",
    "        json=request.model_dump(),\n",
    "        headers={\"X-API-Key\": X_API_KEY},\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# ## Helper Functions\n",
    "#\n",
    "# We provide a comprehensive helper function to convert your data into the format our API expects:\n",
    "\n",
    "\n",
    "def convert_df_to_synthefy_request_with_leaking_context(\n",
    "    df: pd.DataFrame,\n",
    "    future_df: pd.DataFrame | None,\n",
    "    target_cols: List[str],\n",
    "    forecast_timestamps: List[str],\n",
    "    timestamp_col: Optional[str] = None,  # auto-detect if not provided\n",
    "    covariate_cols: List[str] = [],\n",
    "    synthefy_metadata_info_combined: List[HaverMetadataAccessInfo]\n",
    "    | None = None,\n",
    "    synthefy_metadata_leak_idxs: Optional[List[int]] = None,\n",
    "    model_type: str = \"synthefy-forecasting\",\n",
    ") -> FoundationModelForecastStreamRequest:\n",
    "    \"\"\"Convert pandas DataFrames into a Synthefy API request.\n",
    "\n",
    "    This function handles all the data preparation needed to make a forecast request.\n",
    "    It supports:\n",
    "    - Automatic timestamp detection\n",
    "    - Multiple target variables\n",
    "    - Optional covariates\n",
    "    - Future known data\n",
    "    - External data integration\n",
    "\n",
    "    Args:\n",
    "        df: Historical data DataFrame\n",
    "        future_df: Future known data DataFrame (can be empty)\n",
    "        target_cols: Columns to forecast\n",
    "        forecast_timestamps: Timestamps to forecast for\n",
    "        timestamp_col: Column containing timestamps (auto-detected if None)\n",
    "        covariate_cols: Additional columns to use as features\n",
    "        synthefy_metadata_info_combined: External data sources to use\n",
    "        synthefy_metadata_leak_idxs: Which external data sources to use\n",
    "\n",
    "    Returns:\n",
    "        A properly formatted request object for the Synthefy API\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    # auto-detect timestamp column if not provided\n",
    "    if timestamp_col is None:\n",
    "        for col in df.columns:\n",
    "            if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                timestamp_col = col\n",
    "                break\n",
    "    else:\n",
    "        df.loc[:, timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "        if future_df is not None:\n",
    "            future_df.loc[:, timestamp_col] = pd.to_datetime(\n",
    "                future_df[timestamp_col]\n",
    "            )\n",
    "    if not timestamp_col:\n",
    "        raise ValueError(\"No timestamp column found\")\n",
    "\n",
    "    historical_timestamps = [\n",
    "        ts.isoformat() for ts in df[timestamp_col].tolist()\n",
    "    ]\n",
    "\n",
    "    # drop timestamp column from df\n",
    "    df_copy = df_copy.drop(columns=[timestamp_col])\n",
    "\n",
    "    df_copy = df_copy[target_cols + covariate_cols]\n",
    "    historical_timeseries_data = df_copy.to_dict(orient=\"list\")\n",
    "    historical_timeseries_data = {\n",
    "        str(k): v for k, v in historical_timeseries_data.items()\n",
    "    }\n",
    "\n",
    "    # Get the future_timeseries_data (don't give the target columns)\n",
    "    future_timeseries_data = None\n",
    "    if future_df is not None:\n",
    "        future_timeseries_data = future_df[covariate_cols].to_dict(\n",
    "            orient=\"list\"\n",
    "        )\n",
    "        future_timeseries_data = {\n",
    "            str(k): v for k, v in future_timeseries_data.items()\n",
    "        }\n",
    "\n",
    "    # create request object\n",
    "    request = FoundationModelForecastStreamRequest(\n",
    "        historical_timestamps=historical_timestamps,\n",
    "        historical_timeseries_data=historical_timeseries_data,\n",
    "        targets=target_cols,\n",
    "        covariates=covariate_cols,\n",
    "        synthefy_metadata_info_combined=synthefy_metadata_info_combined,\n",
    "        synthefy_metadata_leak_idxs=synthefy_metadata_leak_idxs,\n",
    "        forecast_timestamps=forecast_timestamps,\n",
    "        future_timeseries_data=future_timeseries_data,\n",
    "        static_context=None,  # Not yet supported\n",
    "        prompt=None,  # Not yet supported\n",
    "        quantiles=None,\n",
    "        model_type=model_type,\n",
    "    )\n",
    "\n",
    "    return request\n",
    "\n",
    "def convert_response_to_df(\n",
    "    response: Dict[str, Any],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Convert API response to pandas DataFrames for easy analysis.\n",
    "\n",
    "    Args:\n",
    "        response: The API response dictionary\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (forecast_df, quantiles_df) where:\n",
    "        - forecast_df contains the point forecasts\n",
    "        - quantiles_df contains the forecast quantiles\n",
    "    \"\"\"\n",
    "    forecast_dict = {k: v for k, v in response[\"forecast\"].items()}\n",
    "    quantiles = {k: v for k, v in response[\"forecast_quantiles\"].items()}\n",
    "    forecast_df = pd.DataFrame(forecast_dict)\n",
    "    forecast_df[\"timestamp\"] = response[\"forecast_timestamps\"]\n",
    "    quantiles_df = pd.DataFrame(quantiles)\n",
    "    quantiles_df[\"timestamp\"] = response[\"forecast_timestamps\"]\n",
    "    return forecast_df, quantiles_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>713173.95</td>\n",
       "      <td>0</td>\n",
       "      <td>64.88</td>\n",
       "      <td>3.997</td>\n",
       "      <td>192.013558</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>733455.07</td>\n",
       "      <td>0</td>\n",
       "      <td>64.89</td>\n",
       "      <td>3.985</td>\n",
       "      <td>192.170412</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>734464.36</td>\n",
       "      <td>0</td>\n",
       "      <td>54.47</td>\n",
       "      <td>4.000</td>\n",
       "      <td>192.327265</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>718125.53</td>\n",
       "      <td>0</td>\n",
       "      <td>56.47</td>\n",
       "      <td>3.969</td>\n",
       "      <td>192.330854</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>760281.43</td>\n",
       "      <td>0</td>\n",
       "      <td>58.85</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store        Date  Weekly_Sales  Holiday_Flag  Temperature  \\\n",
       "0      store_1  2010-02-05    1643690.90             0        42.31   \n",
       "1      store_1  2010-02-12    1641957.44             1        38.51   \n",
       "2      store_1  2010-02-19    1611968.17             0        39.93   \n",
       "3      store_1  2010-02-26    1409727.59             0        46.63   \n",
       "4      store_1  2010-03-05    1554806.68             0        46.50   \n",
       "...        ...         ...           ...           ...          ...   \n",
       "6430  store_45  2012-09-28     713173.95             0        64.88   \n",
       "6431  store_45  2012-10-05     733455.07             0        64.89   \n",
       "6432  store_45  2012-10-12     734464.36             0        54.47   \n",
       "6433  store_45  2012-10-19     718125.53             0        56.47   \n",
       "6434  store_45  2012-10-26     760281.43             0        58.85   \n",
       "\n",
       "      Fuel_Price         CPI  Unemployment  \n",
       "0          2.572  211.096358         8.106  \n",
       "1          2.548  211.242170         8.106  \n",
       "2          2.514  211.289143         8.106  \n",
       "3          2.561  211.319643         8.106  \n",
       "4          2.625  211.350143         8.106  \n",
       "...          ...         ...           ...  \n",
       "6430       3.997  192.013558         8.684  \n",
       "6431       3.985  192.170412         8.667  \n",
       "6432       4.000  192.327265         8.667  \n",
       "6433       3.969  192.330854         8.667  \n",
       "6434       3.882  192.308899         8.667  \n",
       "\n",
       "[6435 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/minkyu/repos/synthefy-package/_dev_/fixed_walmart.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>store_1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-09-28</td>\n",
       "      <td>713173.95</td>\n",
       "      <td>0</td>\n",
       "      <td>64.88</td>\n",
       "      <td>3.997</td>\n",
       "      <td>192.013558</td>\n",
       "      <td>8.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>733455.07</td>\n",
       "      <td>0</td>\n",
       "      <td>64.89</td>\n",
       "      <td>3.985</td>\n",
       "      <td>192.170412</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-12</td>\n",
       "      <td>734464.36</td>\n",
       "      <td>0</td>\n",
       "      <td>54.47</td>\n",
       "      <td>4.000</td>\n",
       "      <td>192.327265</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-19</td>\n",
       "      <td>718125.53</td>\n",
       "      <td>0</td>\n",
       "      <td>56.47</td>\n",
       "      <td>3.969</td>\n",
       "      <td>192.330854</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>store_45</td>\n",
       "      <td>2012-10-26</td>\n",
       "      <td>760281.43</td>\n",
       "      <td>0</td>\n",
       "      <td>58.85</td>\n",
       "      <td>3.882</td>\n",
       "      <td>192.308899</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Store        Date  Weekly_Sales  Holiday_Flag  Temperature  \\\n",
       "0      store_1  2010-02-05    1643690.90             0        42.31   \n",
       "1      store_1  2010-02-12    1641957.44             1        38.51   \n",
       "2      store_1  2010-02-19    1611968.17             0        39.93   \n",
       "3      store_1  2010-02-26    1409727.59             0        46.63   \n",
       "4      store_1  2010-03-05    1554806.68             0        46.50   \n",
       "...        ...         ...           ...           ...          ...   \n",
       "6430  store_45  2012-09-28     713173.95             0        64.88   \n",
       "6431  store_45  2012-10-05     733455.07             0        64.89   \n",
       "6432  store_45  2012-10-12     734464.36             0        54.47   \n",
       "6433  store_45  2012-10-19     718125.53             0        56.47   \n",
       "6434  store_45  2012-10-26     760281.43             0        58.85   \n",
       "\n",
       "      Fuel_Price         CPI  Unemployment  \n",
       "0          2.572  211.096358         8.106  \n",
       "1          2.548  211.242170         8.106  \n",
       "2          2.514  211.289143         8.106  \n",
       "3          2.561  211.319643         8.106  \n",
       "4          2.625  211.350143         8.106  \n",
       "...          ...         ...           ...  \n",
       "6430       3.997  192.013558         8.684  \n",
       "6431       3.985  192.170412         8.667  \n",
       "6432       4.000  192.327265         8.667  \n",
       "6433       3.969  192.330854         8.667  \n",
       "6434       3.882  192.308899         8.667  \n",
       "\n",
       "[6435 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last date is 2012-10-26. -> Let's forecast for the next 4 weeks.\n",
    "df = df[df[\"Store\"] == \"store_1\"]\n",
    "\n",
    "# Create a basic forecast request\n",
    "request = convert_df_to_synthefy_request_with_leaking_context(\n",
    "    df=df,\n",
    "    future_df=None,  # No future data in this example\n",
    "    target_cols=[\"Weekly_Sales\"],\n",
    "    forecast_timestamps=[\n",
    "        \"2012-11-02\",\n",
    "        \"2012-11-09\",\n",
    "        \"2012-11-16\",\n",
    "        \"2012-11-23\",\n",
    "    ],\n",
    "    timestamp_col=\"Date\",\n",
    "    covariate_cols=[],\n",
    "    synthefy_metadata_info_combined=None,\n",
    "    synthefy_metadata_leak_idxs=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"historical_timestamps\": [\n",
      "        \"2010-02-05T00:00:00\",\n",
      "        \"2010-02-12T00:00:00\",\n",
      "        \"2010-02-19T00:00:00\",\n",
      "        \"2010-02-26T00:00:00\",\n",
      "        \"2010-03-05T00:00:00\",\n",
      "        \"2010-03-12T00:00:00\",\n",
      "        \"2010-03-19T00:00:00\",\n",
      "        \"2010-03-26T00:00:00\",\n",
      "        \"2010-04-02T00:00:00\",\n",
      "        \"2010-04-09T00:00:00\",\n",
      "        \"2010-04-16T00:00:00\",\n",
      "        \"2010-04-23T00:00:00\",\n",
      "        \"2010-04-30T00:00:00\",\n",
      "        \"2010-05-07T00:00:00\",\n",
      "        \"2010-05-14T00:00:00\",\n",
      "        \"2010-05-21T00:00:00\",\n",
      "        \"2010-05-28T00:00:00\",\n",
      "        \"2010-06-04T00:00:00\",\n",
      "        \"2010-06-11T00:00:00\",\n",
      "        \"2010-06-18T00:00:00\",\n",
      "        \"2010-06-25T00:00:00\",\n",
      "        \"2010-07-02T00:00:00\",\n",
      "        \"2010-07-09T00:00:00\",\n",
      "        \"2010-07-16T00:00:00\",\n",
      "        \"2010-07-23T00:00:00\",\n",
      "        \"2010-07-30T00:00:00\",\n",
      "        \"2010-08-06T00:00:00\",\n",
      "        \"2010-08-13T00:00:00\",\n",
      "        \"2010-08-20T00:00:00\",\n",
      "        \"2010-08-27T00:00:00\",\n",
      "        \"2010-09-03T00:00:00\",\n",
      "        \"2010-09-10T00:00:00\",\n",
      "        \"2010-09-17T00:00:00\",\n",
      "        \"2010-09-24T00:00:00\",\n",
      "        \"2010-10-01T00:00:00\",\n",
      "        \"2010-10-08T00:00:00\",\n",
      "        \"2010-10-15T00:00:00\",\n",
      "        \"2010-10-22T00:00:00\",\n",
      "        \"2010-10-29T00:00:00\",\n",
      "        \"2010-11-05T00:00:00\",\n",
      "        \"2010-11-12T00:00:00\",\n",
      "        \"2010-11-19T00:00:00\",\n",
      "        \"2010-11-26T00:00:00\",\n",
      "        \"2010-12-03T00:00:00\",\n",
      "        \"2010-12-10T00:00:00\",\n",
      "        \"2010-12-17T00:00:00\",\n",
      "        \"2010-12-24T00:00:00\",\n",
      "        \"2010-12-31T00:00:00\",\n",
      "        \"2011-01-07T00:00:00\",\n",
      "        \"2011-01-14T00:00:00\",\n",
      "        \"2011-01-21T00:00:00\",\n",
      "        \"2011-01-28T00:00:00\",\n",
      "        \"2011-02-04T00:00:00\",\n",
      "        \"2011-02-11T00:00:00\",\n",
      "        \"2011-02-18T00:00:00\",\n",
      "        \"2011-02-25T00:00:00\",\n",
      "        \"2011-03-04T00:00:00\",\n",
      "        \"2011-03-11T00:00:00\",\n",
      "        \"2011-03-18T00:00:00\",\n",
      "        \"2011-03-25T00:00:00\",\n",
      "        \"2011-04-01T00:00:00\",\n",
      "        \"2011-04-08T00:00:00\",\n",
      "        \"2011-04-15T00:00:00\",\n",
      "        \"2011-04-22T00:00:00\",\n",
      "        \"2011-04-29T00:00:00\",\n",
      "        \"2011-05-06T00:00:00\",\n",
      "        \"2011-05-13T00:00:00\",\n",
      "        \"2011-05-20T00:00:00\",\n",
      "        \"2011-05-27T00:00:00\",\n",
      "        \"2011-06-03T00:00:00\",\n",
      "        \"2011-06-10T00:00:00\",\n",
      "        \"2011-06-17T00:00:00\",\n",
      "        \"2011-06-24T00:00:00\",\n",
      "        \"2011-07-01T00:00:00\",\n",
      "        \"2011-07-08T00:00:00\",\n",
      "        \"2011-07-15T00:00:00\",\n",
      "        \"2011-07-22T00:00:00\",\n",
      "        \"2011-07-29T00:00:00\",\n",
      "        \"2011-08-05T00:00:00\",\n",
      "        \"2011-08-12T00:00:00\",\n",
      "        \"2011-08-19T00:00:00\",\n",
      "        \"2011-08-26T00:00:00\",\n",
      "        \"2011-09-02T00:00:00\",\n",
      "        \"2011-09-09T00:00:00\",\n",
      "        \"2011-09-16T00:00:00\",\n",
      "        \"2011-09-23T00:00:00\",\n",
      "        \"2011-09-30T00:00:00\",\n",
      "        \"2011-10-07T00:00:00\",\n",
      "        \"2011-10-14T00:00:00\",\n",
      "        \"2011-10-21T00:00:00\",\n",
      "        \"2011-10-28T00:00:00\",\n",
      "        \"2011-11-04T00:00:00\",\n",
      "        \"2011-11-11T00:00:00\",\n",
      "        \"2011-11-18T00:00:00\",\n",
      "        \"2011-11-25T00:00:00\",\n",
      "        \"2011-12-02T00:00:00\",\n",
      "        \"2011-12-09T00:00:00\",\n",
      "        \"2011-12-16T00:00:00\",\n",
      "        \"2011-12-23T00:00:00\",\n",
      "        \"2011-12-30T00:00:00\",\n",
      "        \"2012-01-06T00:00:00\",\n",
      "        \"2012-01-13T00:00:00\",\n",
      "        \"2012-01-20T00:00:00\",\n",
      "        \"2012-01-27T00:00:00\",\n",
      "        \"2012-02-03T00:00:00\",\n",
      "        \"2012-02-10T00:00:00\",\n",
      "        \"2012-02-17T00:00:00\",\n",
      "        \"2012-02-24T00:00:00\",\n",
      "        \"2012-03-02T00:00:00\",\n",
      "        \"2012-03-09T00:00:00\",\n",
      "        \"2012-03-16T00:00:00\",\n",
      "        \"2012-03-23T00:00:00\",\n",
      "        \"2012-03-30T00:00:00\",\n",
      "        \"2012-04-06T00:00:00\",\n",
      "        \"2012-04-13T00:00:00\",\n",
      "        \"2012-04-20T00:00:00\",\n",
      "        \"2012-04-27T00:00:00\",\n",
      "        \"2012-05-04T00:00:00\",\n",
      "        \"2012-05-11T00:00:00\",\n",
      "        \"2012-05-18T00:00:00\",\n",
      "        \"2012-05-25T00:00:00\",\n",
      "        \"2012-06-01T00:00:00\",\n",
      "        \"2012-06-08T00:00:00\",\n",
      "        \"2012-06-15T00:00:00\",\n",
      "        \"2012-06-22T00:00:00\",\n",
      "        \"2012-06-29T00:00:00\",\n",
      "        \"2012-07-06T00:00:00\",\n",
      "        \"2012-07-13T00:00:00\",\n",
      "        \"2012-07-20T00:00:00\",\n",
      "        \"2012-07-27T00:00:00\",\n",
      "        \"2012-08-03T00:00:00\",\n",
      "        \"2012-08-10T00:00:00\",\n",
      "        \"2012-08-17T00:00:00\",\n",
      "        \"2012-08-24T00:00:00\",\n",
      "        \"2012-08-31T00:00:00\",\n",
      "        \"2012-09-07T00:00:00\",\n",
      "        \"2012-09-14T00:00:00\",\n",
      "        \"2012-09-21T00:00:00\",\n",
      "        \"2012-09-28T00:00:00\",\n",
      "        \"2012-10-05T00:00:00\",\n",
      "        \"2012-10-12T00:00:00\",\n",
      "        \"2012-10-19T00:00:00\",\n",
      "        \"2012-10-26T00:00:00\"\n",
      "    ],\n",
      "    \"historical_timeseries_data\": {\n",
      "        \"Weekly_Sales\": [\n",
      "            1643690.9,\n",
      "            1641957.44,\n",
      "            1611968.17,\n",
      "            1409727.59,\n",
      "            1554806.68,\n",
      "            1439541.59,\n",
      "            1472515.79,\n",
      "            1404429.92,\n",
      "            1594968.28,\n",
      "            1545418.53,\n",
      "            1466058.28,\n",
      "            1391256.12,\n",
      "            1425100.71,\n",
      "            1603955.12,\n",
      "            1494251.5,\n",
      "            1399662.07,\n",
      "            1432069.95,\n",
      "            1615524.71,\n",
      "            1542561.09,\n",
      "            1503284.06,\n",
      "            1422711.6,\n",
      "            1492418.14,\n",
      "            1546074.18,\n",
      "            1448938.92,\n",
      "            1385065.2,\n",
      "            1371986.6,\n",
      "            1605491.78,\n",
      "            1508237.76,\n",
      "            1513080.49,\n",
      "            1449142.92,\n",
      "            1540163.53,\n",
      "            1507460.69,\n",
      "            1430378.67,\n",
      "            1351791.03,\n",
      "            1453329.5,\n",
      "            1508239.93,\n",
      "            1459409.1,\n",
      "            1345454.0,\n",
      "            1384209.22,\n",
      "            1551659.28,\n",
      "            1494479.49,\n",
      "            1483784.18,\n",
      "            1955624.11,\n",
      "            1548033.78,\n",
      "            1682614.26,\n",
      "            1891034.93,\n",
      "            2387950.2,\n",
      "            1367320.01,\n",
      "            1444732.28,\n",
      "            1391013.96,\n",
      "            1327405.42,\n",
      "            1316899.31,\n",
      "            1606629.58,\n",
      "            1649614.93,\n",
      "            1686842.78,\n",
      "            1456800.28,\n",
      "            1636263.41,\n",
      "            1553191.63,\n",
      "            1576818.06,\n",
      "            1541102.38,\n",
      "            1495064.75,\n",
      "            1614259.35,\n",
      "            1559889.0,\n",
      "            1564819.81,\n",
      "            1455090.69,\n",
      "            1629391.28,\n",
      "            1604775.58,\n",
      "            1428218.27,\n",
      "            1466046.67,\n",
      "            1635078.41,\n",
      "            1588948.32,\n",
      "            1532114.86,\n",
      "            1438830.15,\n",
      "            1488538.09,\n",
      "            1534849.64,\n",
      "            1455119.97,\n",
      "            1396926.82,\n",
      "            1352219.79,\n",
      "            1624383.75,\n",
      "            1525147.09,\n",
      "            1530761.43,\n",
      "            1464693.46,\n",
      "            1550229.22,\n",
      "            1540471.24,\n",
      "            1514259.78,\n",
      "            1380020.27,\n",
      "            1394561.83,\n",
      "            1630989.95,\n",
      "            1493525.93,\n",
      "            1502562.78,\n",
      "            1445249.09,\n",
      "            1697229.58,\n",
      "            1594938.89,\n",
      "            1539483.7,\n",
      "            2033320.66,\n",
      "            1584083.95,\n",
      "            1799682.38,\n",
      "            1881176.67,\n",
      "            2270188.99,\n",
      "            1497462.72,\n",
      "            1550369.92,\n",
      "            1459601.17,\n",
      "            1394393.84,\n",
      "            1319325.59,\n",
      "            1636339.65,\n",
      "            1802477.43,\n",
      "            1819870.0,\n",
      "            1539387.83,\n",
      "            1688420.76,\n",
      "            1675431.16,\n",
      "            1677472.78,\n",
      "            1511068.07,\n",
      "            1649604.63,\n",
      "            1899676.88,\n",
      "            1621031.7,\n",
      "            1521577.87,\n",
      "            1468928.37,\n",
      "            1684519.99,\n",
      "            1611096.05,\n",
      "            1595901.87,\n",
      "            1555444.55,\n",
      "            1624477.58,\n",
      "            1697230.96,\n",
      "            1630607.0,\n",
      "            1527845.81,\n",
      "            1540421.49,\n",
      "            1769854.16,\n",
      "            1527014.04,\n",
      "            1497954.76,\n",
      "            1439123.71,\n",
      "            1631135.79,\n",
      "            1592409.97,\n",
      "            1597868.05,\n",
      "            1494122.38,\n",
      "            1582083.4,\n",
      "            1661767.33,\n",
      "            1517428.87,\n",
      "            1506126.06,\n",
      "            1437059.26,\n",
      "            1670785.97,\n",
      "            1573072.81,\n",
      "            1508068.77,\n",
      "            1493659.74\n",
      "        ]\n",
      "    },\n",
      "    \"targets\": [\n",
      "        \"Weekly_Sales\"\n",
      "    ],\n",
      "    \"covariates\": [],\n",
      "    \"synthefy_metadata_info_combined\": null,\n",
      "    \"synthefy_metadata_leak_idxs\": null,\n",
      "    \"forecast_timestamps\": [\n",
      "        \"2012-11-02\",\n",
      "        \"2012-11-09\",\n",
      "        \"2012-11-16\",\n",
      "        \"2012-11-23\"\n",
      "    ],\n",
      "    \"future_timeseries_data\": null,\n",
      "    \"static_context\": null,\n",
      "    \"prompt\": null,\n",
      "    \"quantiles\": null,\n",
      "    \"model_type\": \"synthefy-forecasting\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Let's examine our request\n",
    "print(json.dumps(request.model_dump(), indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'synthefy-forecasting'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veryfing we use the synthefy foundation model\n",
    "request.model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forecast_timestamps': ['2012-11-02T00:00:00.000000000', '2012-11-09T00:00:00.000000000', '2012-11-16T00:00:00.000000000', '2012-11-23T00:00:00.000000000'], 'forecast': {'Weekly_Sales': [1630241.0, 1599859.625, 1570059.875, 1569942.625]}, 'forecast_quantiles': {'Weekly_Sales_p10': [0.0, 0.0, 0.0, 0.0], 'Weekly_Sales_p90': [0.0, 0.0, 0.0, 0.0]}}\n",
      "\n",
      "Point Forecasts:\n",
      "   Weekly_Sales                      timestamp\n",
      "0   1630241.000  2012-11-02T00:00:00.000000000\n",
      "1   1599859.625  2012-11-09T00:00:00.000000000\n",
      "2   1570059.875  2012-11-16T00:00:00.000000000\n",
      "3   1569942.625  2012-11-23T00:00:00.000000000\n",
      "\n",
      "Forecast Quantiles:\n",
      "   Weekly_Sales_p10  Weekly_Sales_p90                      timestamp\n",
      "0               0.0               0.0  2012-11-02T00:00:00.000000000\n",
      "1               0.0               0.0  2012-11-09T00:00:00.000000000\n",
      "2               0.0               0.0  2012-11-16T00:00:00.000000000\n",
      "3               0.0               0.0  2012-11-23T00:00:00.000000000\n"
     ]
    }
   ],
   "source": [
    "# Make the API call\n",
    "response = make_api_call(request)\n",
    "\n",
    "print(response.json())\n",
    "\n",
    "\n",
    "# Convert response to DataFrames for analysis\n",
    "forecast_df, quantiles_df = convert_response_to_df(response.json())\n",
    "print(\"\\nPoint Forecasts:\")\n",
    "print(forecast_df.head())\n",
    "print(\"\\nForecast Quantiles:\")\n",
    "print(quantiles_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Using Future Known Data\n",
    "\n",
    "Now, let's enhance our forecast by incorporating known future data. This is useful when you have\n",
    "information about future events that might affect your target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Store                 Date  Weekly_Sales  Holiday_Flag  Temperature  \\\n",
      "130  store_1  2012-08-03 00:00:00    1631135.79             0        86.11   \n",
      "131  store_1  2012-08-10 00:00:00    1592409.97             0        85.05   \n",
      "132  store_1  2012-08-17 00:00:00    1597868.05             0        84.85   \n",
      "133  store_1  2012-08-24 00:00:00    1494122.38             0        77.66   \n",
      "134  store_1  2012-08-31 00:00:00    1582083.40             0        80.49   \n",
      "\n",
      "     Fuel_Price         CPI  Unemployment  \n",
      "130       3.417  221.949864         6.908  \n",
      "131       3.494  221.958433         6.908  \n",
      "132       3.571  222.038411         6.908  \n",
      "133       3.620  222.171946         6.908  \n",
      "134       3.638  222.305480         6.908  \n",
      "       Store                 Date  Weekly_Sales  Holiday_Flag  Temperature  \\\n",
      "135  store_1  2012-09-07 00:00:00    1661767.33             1        83.96   \n",
      "136  store_1  2012-09-14 00:00:00    1517428.87             0        74.97   \n",
      "137  store_1  2012-09-21 00:00:00    1506126.06             0        69.87   \n",
      "138  store_1  2012-09-28 00:00:00    1437059.26             0        76.08   \n",
      "139  store_1  2012-10-05 00:00:00    1670785.97             0        68.55   \n",
      "\n",
      "     Fuel_Price         CPI  Unemployment  \n",
      "135       3.730  222.439015         6.908  \n",
      "136       3.717  222.582019         6.908  \n",
      "137       3.721  222.781839         6.908  \n",
      "138       3.666  222.981658         6.908  \n",
      "139       3.617  223.181477         6.573  \n"
     ]
    }
   ],
   "source": [
    "# Split our data into historical and future portions\n",
    "historical_df = df[df[\"Date\"] < pd.Timestamp(\"2012-09-01\")]\n",
    "future_df = df[df[\"Date\"] >= pd.Timestamp(\"2012-09-01\")]\n",
    "print(historical_df.tail())\n",
    "print(future_df.head())\n",
    "\n",
    "# Create a request with future known data\n",
    "request = convert_df_to_synthefy_request_with_leaking_context(\n",
    "    df=historical_df,\n",
    "    future_df=future_df,\n",
    "    target_cols=[\"Weekly_Sales\", \"Unemployment\"],\n",
    "    forecast_timestamps=[ts.isoformat() for ts in future_df[\"Date\"].tolist()],\n",
    "    timestamp_col=\"Date\",\n",
    "    covariate_cols=[\"Holiday_Flag\", \"CPI\"],\n",
    "    synthefy_metadata_info_combined=None,\n",
    "    synthefy_metadata_leak_idxs=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Point Forecasts:\n",
      "   Weekly_Sales  Unemployment                      timestamp\n",
      "0   1631153.750      7.771542  2012-09-07T00:00:00.000000000\n",
      "1   1573854.250      7.781507  2012-09-14T00:00:00.000000000\n",
      "2   1567910.250      7.741852  2012-09-21T00:00:00.000000000\n",
      "3   1565830.625      7.734254  2012-09-28T00:00:00.000000000\n",
      "4   1563406.000      7.766744  2012-10-05T00:00:00.000000000\n",
      "\n",
      "Forecast Quantiles:\n",
      "   Weekly_Sales_p10  Weekly_Sales_p90  Unemployment_p10  Unemployment_p90  \\\n",
      "0               0.0               0.0               0.0               0.0   \n",
      "1               0.0               0.0               0.0               0.0   \n",
      "2               0.0               0.0               0.0               0.0   \n",
      "3               0.0               0.0               0.0               0.0   \n",
      "4               0.0               0.0               0.0               0.0   \n",
      "\n",
      "                       timestamp  \n",
      "0  2012-09-07T00:00:00.000000000  \n",
      "1  2012-09-14T00:00:00.000000000  \n",
      "2  2012-09-21T00:00:00.000000000  \n",
      "3  2012-09-28T00:00:00.000000000  \n",
      "4  2012-10-05T00:00:00.000000000  \n"
     ]
    }
   ],
   "source": [
    "# Make the API call\n",
    "response = make_api_call(request)\n",
    "\n",
    "# Convert response to DataFrames for analysis\n",
    "forecast_df, quantiles_df = convert_response_to_df(response.json())\n",
    "print(\"\\nPoint Forecasts:\")\n",
    "print(forecast_df.head())\n",
    "print(\"\\nForecast Quantiles:\")\n",
    "print(quantiles_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Now that you've seen the basics of using the Synthefy Forecasting API, you can:\n",
    "1. Try different combinations of targets and covariates\n",
    "2. Experiment with different external data sources\n",
    "3. Adjust the forecast horizon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
